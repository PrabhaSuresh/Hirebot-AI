

# ğŸ“ Hirebot AI â€“ MCP Enabled (`mcp_enabled_hirebot_agent2`)

ğŸš€ An advanced, modular AI job matching system powered by **Model Context Protocol (MCP)**, leveraging **LLMs** and real-time scraping to deliver personalized LinkedIn job recommendations.

---

## ğŸ“Œ Project Highlights

- ğŸ§  MCP-based agent coordination
- ğŸ“„ Resume parsing from PDFs using SpaCy + PyMuPDF
- ğŸŒ Real-time job listing fetch via Apify LinkedIn Scraper
- ğŸ¤– Job scoring using Meta LLaMA 3 via Together AI
- ğŸ§© Modular design with reusable shared models
- ğŸ–¥ï¸ Web UI via `templates/index.html` (Flask backend)

---

## ğŸ“‚ Folder Structure

```
mcp_enabled_hirebot_agent2/
â”‚
â”œâ”€â”€ client_server.py           # Flask backend to serve the UI and handle user input
â”œâ”€â”€ linkedin-scraper.py        # Scraper agent that pulls LinkedIn jobs using Apify
â”œâ”€â”€ scoring-calculator.py      # Scoring agent that uses LLM to rank job matches
â”œâ”€â”€ shared_models.py           # Common utilities or schema across agents
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Simple web frontend for resume upload
â”œâ”€â”€ .env                       # Environment variables (API keys, config)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml             # Project dependencies/config (used by `uv` or `hatch`)
â”œâ”€â”€ uv.lock                    # Lock file for reproducible environments
â””â”€â”€ README.md                  # You're here!
```

---

## ğŸ› ï¸ Tech Stack

| Component              | Technology                              |
|------------------------|------------------------------------------|
| Backend/API            | Flask + Python                          |
| Parsing                | SpaCy, PyMuPDF                          |
| Scraping               | Apify (LinkedIn data)                   |
| AI/LLM Scoring         | Meta LLaMA 3 via Together.ai            |
| Coordination Protocol  | Model Context Protocol (MCP)           |
| Frontend               | HTML (Jinja via Flask)                  |

---

## ğŸ” Workflow

1. **User uploads resume** via `index.html` â†’ `client_server.py`.
2. **Resume Parsing** extracts skills & experience.
3. **LinkedIn Scraper Agent** fetches relevant job listings.
4. **Scoring Agent** sends data to Together.ai LLM â†’ returns ranked jobs.
5. **Client displays** top results to the user.

Agents share state through a **shared context** using MCP.

---

## ğŸš€ Getting Started

```bash
# Clone the repo
git clone https://github.com/PrabhaSuresh/Hirebot-AI.git
cd Hirebot-AI/mcp_enabled_hirebot_agent2

# Setup virtual environment
python -m venv .venv
source .venv/bin/activate      # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

> Make sure to configure your `.env` file with:
```
TOGETHER_API_KEY=your_key
APIFY_API_TOKEN=your_token
```

---

## âœ… Run the App

```bash
python client_server.py
```

Then visit: [http://localhost:5000](http://localhost:5000)

---

## ğŸŒ± Future Enhancements

- ğŸ“„ Cover Letter Generator Agent  
- ğŸ§  AI Feedback Loop for Job Preferences  
- ğŸ—‚ï¸ Skill Matching & Gap Detection

---

## ğŸ“ƒ License

MIT License

---

## ğŸ™Œ Acknowledgements

- [Together.ai](https://www.together.ai/)
- [Apify](https://apify.com/)
- [LangChain](https://www.langchain.com/)
- [Model Context Protocol (MCP)](https://github.com/mcprotocol/mcp)
